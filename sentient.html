<html><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="style.css" type="text/css" />
    <title>Milić Vukojičić's Personal Site</title>
    <link rel="icon" href="logo.png">
  </head>
  
    <body>
      <header class='header'>
    <a class="logo" href="https://www.милићвукојичић.од.срб/"> <img src="logo.png" alt="logo"width="50" height="50"></a>
    <nav>
      <a href="https://www.милићвукојичић.од.срб/writings.html">writings</a>
      <a href="https://www.милићвукојичић.од.срб/recommendations.html">recommendations</a>
      <a href="https://www.милићвукојичић.од.срб/teaching.html">teaching</a>  
      <a href="https://www.милићвукојичић.од.срб/code.html">code</a>
      <a href="https://www.милићвукојичић.од.срб/pnni.html">pnni</a>
      <a href="https://www.милићвукојичић.од.срб/personal.html">personal</a>
      <a href="https://www.милићвукојичић.од.срб/indexsr.html">serbian</a>
    </nav>
  </header>
<h2 id="&amp;#8220;Sentient&amp;#8221;%20AI%20called%20LaMDA">&#8220;Sentient&#8221; AI called LaMDA</h2>

<p>Google engineer Blake Lemoine &#8220;claims that LaMDA AI is sentient&#8221;.</p>

<p><a href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/">https:&#47;&#47;www.washingtonpost.com&#47;technology&#47;2022&#47;06&#47;11&#47;google-ai-lamda-blake-lemoine&#47;</a></p>

<p>We can agree that this statement &#8220;Sentient AI&#8221; is a very very important one for computer scientists, neuroscientists, psychologists, philosophers, and mathematicians… So, claims like this one can be very important for the human race. If we use the term &#8220;Sentient AI&#8221; just like a buzzword, this can do harm to all of the fields above and lead to many misunderstandings and many loose definitions of the words.</p>

<p>First, we need to understand what is behind the curtain. Let&#8217;s cite the part of text from the LaMDA webpage:</p>

<p>&#8220;LaMDA’s conversational skills have been years in the making. Like many recent language models, including BERT and GPT-3, it’s built on Transformer…</p>

<p><a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">https:&#47;&#47;ai.googleblog.com&#47;2017&#47;08&#47;transformer-novel-neural-network.html</a></p>

<p>That architecture produces a model that can be trained to read many words (a sentence or paragraph, for example), pay attention to how those words relate to one another, and then predict what words it thinks will come next…&#8221;</p>

<p>Based on the claims we can see that the technology behind the LaMDA is based on the Transformer - Neural Network Architecture for Language Understanding(AI-Language Models (<a href="https://www.youtube.com/watch?v=rURRYI66E54">https:&#47;&#47;www.youtube.com&#47;watch?v=rURRYI66E54</a>) Transformers, No, it&#8217;s not Sentient (<a href="https://www.youtube.com/watch?v=iBouACLc-hw&amp;t=1s">https:&#47;&#47;www.youtube.com&#47;watch?v=iBouACLc-hw&#38;t=1s</a>)), this means that input to the model contains only words and the output from the model contains only words.</p>

<p>The main question is can we define this model as &#8220;sentient&#8221;? Can we define the model that just takes words as an input, does some computation over these words, and outputs words, a &#8220;sentient&#8221; model?</p>

<p>The answer is very strange, if we define sentient as one way (minimalistic) to define consciousness according to Antonio Damasio, a leading neuroscientist, this means that claiming that AI is &#8220;sentient&#8221; is the same to claim that AI is conscious and has a mind.</p>

<p>So, in the end, LaMDA AI can not be categorized as sentient.</p>
<footer>
    <hr>
    <p>Copyright © 2022 Milić Vukojičić All text is released under CC-BY 4.0 license and all source code is released under GNU General Public License v3.0.</p>
</footer> 
