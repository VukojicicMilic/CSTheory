<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html; charset=ISO-8859-1" http-equiv="content-type">
  <title>"Sentient" AI called LaMDA</title>
</head>
<body>
<h2 style="text-align: justify;" id="org9977472">"Sentient" AI called LaMDA</h2>
<div style="text-align: justify;">
</div>
<div style="text-align: justify;" class="outline-text-2" id="text-3">
<p>
Google engineer Blake Lemoine "claims that LaMDA AI is sentient".
</p>


<p>
<a href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/">https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/</a>
</p>


<p>
We can agree that this statement "Sentient AI" is a very very important 
one for computer scientists, neuroscientists, psychologists, 
philosophers, and mathematicians&hellip; So, claims like this one can be very 
important for the human race. If we use the term "Sentient AI" just like
 a buzzword, this can do harm to all of the fields above and lead to 
many misunderstandings and many loose definitions of the words. 
</p>


<p>
First, we need to understand what is behind the curtain. Let's cite the part of text from the LaMDA webpage: 
</p>


<p>
"LaMDA&rsquo;s conversational skills have been years in the making. Like many 
recent language models, including BERT and GPT-3, it&rsquo;s built on 
Transformer&hellip;
</p>


<p>
<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</a>
</p>


<p>
That architecture produces a model that can be trained to read many 
words (a sentence or paragraph, for example), pay attention to how those
 words relate to one another, and then predict what words it thinks will
 come next&hellip;"
</p>


<p>
Based on the claims we can see that the technology behind the LaMDA is 
based on the Transformer - Neural Network Architecture for Language 
Understanding(AI-Language Models (<a href="https://www.youtube.com/watch?v=rURRYI66E54">https://www.youtube.com/watch?v=rURRYI66E54</a>) Transformers, No, it's not Sentient (<a href="https://www.youtube.com/watch?v=iBouACLc-hw&amp;t=1s">https://www.youtube.com/watch?v=iBouACLc-hw&amp;t=1s</a>)), this means that input to the model contains only words and the output from the model contains only words. 
</p>


<p>
The main question is can we define this model as "sentient"? 
Can we define the model that just takes words as an input, does some 
computation over these words, and outputs words, a "sentient" model?
</p>


<p>
The answer is very strange, if we define sentient as one way 
(minimalistic) to define consciousness according to Antonio Damasio, a 
leading neuroscientist, this means that claiming that AI is "sentient" 
is the same to claim that AI is conscious and has a mind.
</p>


<p>
So, in the end, LaMDA AI can not be categorized as sentient.
</p>

</div>
</body>
</html>
